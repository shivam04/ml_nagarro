{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>readmitted</th>\n",
       "      <th>x</th>\n",
       "      <th>...</th>\n",
       "      <th>x.6.3</th>\n",
       "      <th>x.13.1</th>\n",
       "      <th>x.3.5</th>\n",
       "      <th>x.8.3</th>\n",
       "      <th>x.11.2</th>\n",
       "      <th>x.18.1</th>\n",
       "      <th>x.72</th>\n",
       "      <th>x.263</th>\n",
       "      <th>x.276</th>\n",
       "      <th>training_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.784698</td>\n",
       "      <td>0.292344</td>\n",
       "      <td>-0.247341</td>\n",
       "      <td>-0.579531</td>\n",
       "      <td>-0.261276</td>\n",
       "      <td>-0.206332</td>\n",
       "      <td>-0.302125</td>\n",
       "      <td>-2.300532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.474839</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.086339</td>\n",
       "      <td>-0.274604</td>\n",
       "      <td>-0.254056</td>\n",
       "      <td>-0.262402</td>\n",
       "      <td>-0.278155</td>\n",
       "      <td>-0.422036</td>\n",
       "      <td>-0.967392</td>\n",
       "      <td>-0.282538</td>\n",
       "      <td>-0.24487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.229955</td>\n",
       "      <td>0.292344</td>\n",
       "      <td>-0.816030</td>\n",
       "      <td>-1.302427</td>\n",
       "      <td>-0.261276</td>\n",
       "      <td>-0.206332</td>\n",
       "      <td>-0.302125</td>\n",
       "      <td>-2.300532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.105940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920506</td>\n",
       "      <td>-0.274604</td>\n",
       "      <td>-0.254056</td>\n",
       "      <td>-0.262402</td>\n",
       "      <td>-0.278155</td>\n",
       "      <td>2.369422</td>\n",
       "      <td>-0.967392</td>\n",
       "      <td>-0.282538</td>\n",
       "      <td>-0.24487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568172</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>1.458724</td>\n",
       "      <td>-0.097600</td>\n",
       "      <td>-0.261276</td>\n",
       "      <td>-0.206332</td>\n",
       "      <td>2.922323</td>\n",
       "      <td>-0.712431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.105940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920506</td>\n",
       "      <td>-0.274604</td>\n",
       "      <td>-0.254056</td>\n",
       "      <td>-0.262402</td>\n",
       "      <td>-0.278155</td>\n",
       "      <td>-0.422036</td>\n",
       "      <td>-0.967392</td>\n",
       "      <td>-0.282538</td>\n",
       "      <td>-0.24487</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.582825</td>\n",
       "      <td>0.442371</td>\n",
       "      <td>-0.247341</td>\n",
       "      <td>0.022883</td>\n",
       "      <td>-0.261276</td>\n",
       "      <td>-0.206332</td>\n",
       "      <td>-0.302125</td>\n",
       "      <td>0.875671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.474839</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.086339</td>\n",
       "      <td>-0.274604</td>\n",
       "      <td>-0.254056</td>\n",
       "      <td>-0.262402</td>\n",
       "      <td>-0.278155</td>\n",
       "      <td>2.369422</td>\n",
       "      <td>-0.967392</td>\n",
       "      <td>-0.282538</td>\n",
       "      <td>-0.24487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.273913</td>\n",
       "      <td>-1.107909</td>\n",
       "      <td>-0.816030</td>\n",
       "      <td>-0.097600</td>\n",
       "      <td>2.465632</td>\n",
       "      <td>1.693810</td>\n",
       "      <td>2.922323</td>\n",
       "      <td>-0.183063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.474839</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.086339</td>\n",
       "      <td>-0.274604</td>\n",
       "      <td>-0.254056</td>\n",
       "      <td>-0.262402</td>\n",
       "      <td>-0.278155</td>\n",
       "      <td>-0.422036</td>\n",
       "      <td>1.033688</td>\n",
       "      <td>-0.282538</td>\n",
       "      <td>-0.24487</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_in_hospital  num_lab_procedures  num_procedures  num_medications  \\\n",
       "0         -0.784698            0.292344       -0.247341        -0.579531   \n",
       "1          0.229955            0.292344       -0.816030        -1.302427   \n",
       "2          0.568172            0.092308        1.458724        -0.097600   \n",
       "3          1.582825            0.442371       -0.247341         0.022883   \n",
       "4          3.273913           -1.107909       -0.816030        -0.097600   \n",
       "\n",
       "   number_outpatient  number_emergency  number_inpatient  number_diagnoses  \\\n",
       "0          -0.261276         -0.206332         -0.302125         -2.300532   \n",
       "1          -0.261276         -0.206332         -0.302125         -2.300532   \n",
       "2          -0.261276         -0.206332          2.922323         -0.712431   \n",
       "3          -0.261276         -0.206332         -0.302125          0.875671   \n",
       "4           2.465632          1.693810          2.922323         -0.183063   \n",
       "\n",
       "   readmitted         x       ...           x.6.3    x.13.1     x.3.5  \\\n",
       "0         NaN -0.474839       ...       -1.086339 -0.274604 -0.254056   \n",
       "1         NaN  2.105940       ...        0.920506 -0.274604 -0.254056   \n",
       "2         NaN  2.105940       ...        0.920506 -0.274604 -0.254056   \n",
       "3         NaN -0.474839       ...       -1.086339 -0.274604 -0.254056   \n",
       "4         NaN -0.474839       ...       -1.086339 -0.274604 -0.254056   \n",
       "\n",
       "      x.8.3    x.11.2    x.18.1      x.72     x.263    x.276  training_label  \n",
       "0 -0.262402 -0.278155 -0.422036 -0.967392 -0.282538 -0.24487               3  \n",
       "1 -0.262402 -0.278155  2.369422 -0.967392 -0.282538 -0.24487               3  \n",
       "2 -0.262402 -0.278155 -0.422036 -0.967392 -0.282538 -0.24487               2  \n",
       "3 -0.262402 -0.278155  2.369422 -0.967392 -0.282538 -0.24487               3  \n",
       "4 -0.262402 -0.278155 -0.422036  1.033688 -0.282538 -0.24487               2  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t = pd.read_csv('train.csv')\n",
    "train_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]), array([ 4901, 17300, 32704]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_t['training_label'],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>x</th>\n",
       "      <th>x.2</th>\n",
       "      <th>...</th>\n",
       "      <th>x.6.3</th>\n",
       "      <th>x.13.1</th>\n",
       "      <th>x.3.5</th>\n",
       "      <th>x.8.3</th>\n",
       "      <th>x.11.2</th>\n",
       "      <th>x.18.1</th>\n",
       "      <th>x.72</th>\n",
       "      <th>x.263</th>\n",
       "      <th>x.276</th>\n",
       "      <th>test_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.785344</td>\n",
       "      <td>-0.657165</td>\n",
       "      <td>2.577013</td>\n",
       "      <td>-0.097341</td>\n",
       "      <td>-0.267341</td>\n",
       "      <td>-0.225309</td>\n",
       "      <td>-0.302265</td>\n",
       "      <td>0.875792</td>\n",
       "      <td>2.105173</td>\n",
       "      <td>-1.829516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922331</td>\n",
       "      <td>-0.274221</td>\n",
       "      <td>-0.253365</td>\n",
       "      <td>-0.263471</td>\n",
       "      <td>-0.276135</td>\n",
       "      <td>-0.421407</td>\n",
       "      <td>1.030376</td>\n",
       "      <td>3.553004</td>\n",
       "      <td>-0.244912</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.122811</td>\n",
       "      <td>-1.656848</td>\n",
       "      <td>0.312642</td>\n",
       "      <td>-1.301251</td>\n",
       "      <td>-0.267341</td>\n",
       "      <td>-0.225309</td>\n",
       "      <td>-0.302265</td>\n",
       "      <td>-1.246853</td>\n",
       "      <td>-0.475012</td>\n",
       "      <td>0.546583</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.084190</td>\n",
       "      <td>-0.274221</td>\n",
       "      <td>-0.253365</td>\n",
       "      <td>-0.263471</td>\n",
       "      <td>-0.276135</td>\n",
       "      <td>-0.421407</td>\n",
       "      <td>1.030376</td>\n",
       "      <td>3.553004</td>\n",
       "      <td>-0.244912</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.227060</td>\n",
       "      <td>-0.107339</td>\n",
       "      <td>-0.819543</td>\n",
       "      <td>0.384223</td>\n",
       "      <td>-0.267341</td>\n",
       "      <td>1.913455</td>\n",
       "      <td>-0.302265</td>\n",
       "      <td>0.875792</td>\n",
       "      <td>2.105173</td>\n",
       "      <td>-1.829516</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.084190</td>\n",
       "      <td>-0.274221</td>\n",
       "      <td>-0.253365</td>\n",
       "      <td>-0.263471</td>\n",
       "      <td>-0.276135</td>\n",
       "      <td>2.372959</td>\n",
       "      <td>-0.970501</td>\n",
       "      <td>-0.281447</td>\n",
       "      <td>-0.244912</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.227060</td>\n",
       "      <td>0.142582</td>\n",
       "      <td>-0.819543</td>\n",
       "      <td>-0.819687</td>\n",
       "      <td>-0.267341</td>\n",
       "      <td>-0.225309</td>\n",
       "      <td>-0.302265</td>\n",
       "      <td>-1.777515</td>\n",
       "      <td>-0.475012</td>\n",
       "      <td>0.546583</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.084190</td>\n",
       "      <td>-0.274221</td>\n",
       "      <td>-0.253365</td>\n",
       "      <td>-0.263471</td>\n",
       "      <td>-0.276135</td>\n",
       "      <td>-0.421407</td>\n",
       "      <td>1.030376</td>\n",
       "      <td>-0.281447</td>\n",
       "      <td>-0.244912</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.914400</td>\n",
       "      <td>-0.307275</td>\n",
       "      <td>2.010921</td>\n",
       "      <td>0.023050</td>\n",
       "      <td>-0.267341</td>\n",
       "      <td>1.913455</td>\n",
       "      <td>-0.302265</td>\n",
       "      <td>-0.716192</td>\n",
       "      <td>2.105173</td>\n",
       "      <td>-1.829516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922331</td>\n",
       "      <td>-0.274221</td>\n",
       "      <td>-0.253365</td>\n",
       "      <td>-0.263471</td>\n",
       "      <td>-0.276135</td>\n",
       "      <td>2.372959</td>\n",
       "      <td>-0.970501</td>\n",
       "      <td>-0.281447</td>\n",
       "      <td>-0.244912</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_in_hospital  num_lab_procedures  num_procedures  num_medications  \\\n",
       "0         -0.785344           -0.657165        2.577013        -0.097341   \n",
       "1         -1.122811           -1.656848        0.312642        -1.301251   \n",
       "2          0.227060           -0.107339       -0.819543         0.384223   \n",
       "3          0.227060            0.142582       -0.819543        -0.819687   \n",
       "4          1.914400           -0.307275        2.010921         0.023050   \n",
       "\n",
       "   number_outpatient  number_emergency  number_inpatient  number_diagnoses  \\\n",
       "0          -0.267341         -0.225309         -0.302265          0.875792   \n",
       "1          -0.267341         -0.225309         -0.302265         -1.246853   \n",
       "2          -0.267341          1.913455         -0.302265          0.875792   \n",
       "3          -0.267341         -0.225309         -0.302265         -1.777515   \n",
       "4          -0.267341          1.913455         -0.302265         -0.716192   \n",
       "\n",
       "          x       x.2     ...         x.6.3    x.13.1     x.3.5     x.8.3  \\\n",
       "0  2.105173 -1.829516     ...      0.922331 -0.274221 -0.253365 -0.263471   \n",
       "1 -0.475012  0.546583     ...     -1.084190 -0.274221 -0.253365 -0.263471   \n",
       "2  2.105173 -1.829516     ...     -1.084190 -0.274221 -0.253365 -0.263471   \n",
       "3 -0.475012  0.546583     ...     -1.084190 -0.274221 -0.253365 -0.263471   \n",
       "4  2.105173 -1.829516     ...      0.922331 -0.274221 -0.253365 -0.263471   \n",
       "\n",
       "     x.11.2    x.18.1      x.72     x.263     x.276  test_label  \n",
       "0 -0.276135 -0.421407  1.030376  3.553004 -0.244912           3  \n",
       "1 -0.276135 -0.421407  1.030376  3.553004 -0.244912           3  \n",
       "2 -0.276135  2.372959 -0.970501 -0.281447 -0.244912           3  \n",
       "3 -0.276135 -0.421407  1.030376 -0.281447 -0.244912           3  \n",
       "4 -0.276135  2.372959 -0.970501 -0.281447 -0.244912           3  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_t = pd.read_csv('test.csv')\n",
    "test_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]), array([ 131, 3600, 9800]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_t['test_label'],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_in_hospital num_lab_procedures num_procedures num_medications number_outpatient number_emergency number_inpatient number_diagnoses x x.2 x.716 x.1.1 x.4.1 x.5 x.6 x.7 x.8 x.718 x.1.3 x.2.3 x.5.1 x.719 x.2.4 x.5.2 x.720 x.6.3 x.13.1 x.3.5 x.8.3 x.11.2 x.18.1 x.72 x.263 x.276 test_label\n"
     ]
    }
   ],
   "source": [
    "fk = dict()\n",
    "for k in test_t:\n",
    "    fk[k] = 1\n",
    "    print k,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_in_hospital 1\n",
      "num_lab_procedures 1\n",
      "num_procedures 1\n",
      "num_medications 1\n",
      "number_outpatient 1\n",
      "number_emergency 1\n",
      "number_inpatient 1\n",
      "number_diagnoses 1\n",
      "x 1\n",
      "x.2 1\n",
      "x.716 1\n",
      "x.1.1 1\n",
      "x.4.1 1\n",
      "x.5 1\n",
      "x.6 1\n",
      "x.7 1\n",
      "x.8 1\n",
      "x.718 1\n",
      "x.1.3 1\n",
      "x.2.3 1\n",
      "x.5.1 1\n",
      "x.719 1\n",
      "x.2.4 1\n",
      "x.5.2 1\n",
      "x.720 1\n",
      "x.6.3 1\n",
      "x.13.1 1\n",
      "x.3.5 1\n",
      "x.8.3 1\n",
      "x.11.2 1\n",
      "x.18.1 1\n",
      "x.72 1\n",
      "x.263 1\n",
      "x.276 1\n",
      "test_label 1\n"
     ]
    }
   ],
   "source": [
    "for k in test_t:\n",
    "    print k,fk[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>x</th>\n",
       "      <th>x.2</th>\n",
       "      <th>...</th>\n",
       "      <th>x.6.3</th>\n",
       "      <th>x.13.1</th>\n",
       "      <th>x.3.5</th>\n",
       "      <th>x.8.3</th>\n",
       "      <th>x.11.2</th>\n",
       "      <th>x.18.1</th>\n",
       "      <th>x.72</th>\n",
       "      <th>x.263</th>\n",
       "      <th>x.276</th>\n",
       "      <th>test_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.785344</td>\n",
       "      <td>-0.657165</td>\n",
       "      <td>2.577013</td>\n",
       "      <td>-0.097341</td>\n",
       "      <td>-0.267341</td>\n",
       "      <td>-0.225309</td>\n",
       "      <td>-0.302265</td>\n",
       "      <td>0.875792</td>\n",
       "      <td>2.105173</td>\n",
       "      <td>-1.829516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922331</td>\n",
       "      <td>-0.274221</td>\n",
       "      <td>-0.253365</td>\n",
       "      <td>-0.263471</td>\n",
       "      <td>-0.276135</td>\n",
       "      <td>-0.421407</td>\n",
       "      <td>1.030376</td>\n",
       "      <td>3.553004</td>\n",
       "      <td>-0.244912</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.122811</td>\n",
       "      <td>-1.656848</td>\n",
       "      <td>0.312642</td>\n",
       "      <td>-1.301251</td>\n",
       "      <td>-0.267341</td>\n",
       "      <td>-0.225309</td>\n",
       "      <td>-0.302265</td>\n",
       "      <td>-1.246853</td>\n",
       "      <td>-0.475012</td>\n",
       "      <td>0.546583</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.084190</td>\n",
       "      <td>-0.274221</td>\n",
       "      <td>-0.253365</td>\n",
       "      <td>-0.263471</td>\n",
       "      <td>-0.276135</td>\n",
       "      <td>-0.421407</td>\n",
       "      <td>1.030376</td>\n",
       "      <td>3.553004</td>\n",
       "      <td>-0.244912</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.227060</td>\n",
       "      <td>-0.107339</td>\n",
       "      <td>-0.819543</td>\n",
       "      <td>0.384223</td>\n",
       "      <td>-0.267341</td>\n",
       "      <td>1.913455</td>\n",
       "      <td>-0.302265</td>\n",
       "      <td>0.875792</td>\n",
       "      <td>2.105173</td>\n",
       "      <td>-1.829516</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.084190</td>\n",
       "      <td>-0.274221</td>\n",
       "      <td>-0.253365</td>\n",
       "      <td>-0.263471</td>\n",
       "      <td>-0.276135</td>\n",
       "      <td>2.372959</td>\n",
       "      <td>-0.970501</td>\n",
       "      <td>-0.281447</td>\n",
       "      <td>-0.244912</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.227060</td>\n",
       "      <td>0.142582</td>\n",
       "      <td>-0.819543</td>\n",
       "      <td>-0.819687</td>\n",
       "      <td>-0.267341</td>\n",
       "      <td>-0.225309</td>\n",
       "      <td>-0.302265</td>\n",
       "      <td>-1.777515</td>\n",
       "      <td>-0.475012</td>\n",
       "      <td>0.546583</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.084190</td>\n",
       "      <td>-0.274221</td>\n",
       "      <td>-0.253365</td>\n",
       "      <td>-0.263471</td>\n",
       "      <td>-0.276135</td>\n",
       "      <td>-0.421407</td>\n",
       "      <td>1.030376</td>\n",
       "      <td>-0.281447</td>\n",
       "      <td>-0.244912</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.914400</td>\n",
       "      <td>-0.307275</td>\n",
       "      <td>2.010921</td>\n",
       "      <td>0.023050</td>\n",
       "      <td>-0.267341</td>\n",
       "      <td>1.913455</td>\n",
       "      <td>-0.302265</td>\n",
       "      <td>-0.716192</td>\n",
       "      <td>2.105173</td>\n",
       "      <td>-1.829516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922331</td>\n",
       "      <td>-0.274221</td>\n",
       "      <td>-0.253365</td>\n",
       "      <td>-0.263471</td>\n",
       "      <td>-0.276135</td>\n",
       "      <td>2.372959</td>\n",
       "      <td>-0.970501</td>\n",
       "      <td>-0.281447</td>\n",
       "      <td>-0.244912</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_in_hospital  num_lab_procedures  num_procedures  num_medications  \\\n",
       "0         -0.785344           -0.657165        2.577013        -0.097341   \n",
       "1         -1.122811           -1.656848        0.312642        -1.301251   \n",
       "2          0.227060           -0.107339       -0.819543         0.384223   \n",
       "3          0.227060            0.142582       -0.819543        -0.819687   \n",
       "4          1.914400           -0.307275        2.010921         0.023050   \n",
       "\n",
       "   number_outpatient  number_emergency  number_inpatient  number_diagnoses  \\\n",
       "0          -0.267341         -0.225309         -0.302265          0.875792   \n",
       "1          -0.267341         -0.225309         -0.302265         -1.246853   \n",
       "2          -0.267341          1.913455         -0.302265          0.875792   \n",
       "3          -0.267341         -0.225309         -0.302265         -1.777515   \n",
       "4          -0.267341          1.913455         -0.302265         -0.716192   \n",
       "\n",
       "          x       x.2     ...         x.6.3    x.13.1     x.3.5     x.8.3  \\\n",
       "0  2.105173 -1.829516     ...      0.922331 -0.274221 -0.253365 -0.263471   \n",
       "1 -0.475012  0.546583     ...     -1.084190 -0.274221 -0.253365 -0.263471   \n",
       "2  2.105173 -1.829516     ...     -1.084190 -0.274221 -0.253365 -0.263471   \n",
       "3 -0.475012  0.546583     ...     -1.084190 -0.274221 -0.253365 -0.263471   \n",
       "4  2.105173 -1.829516     ...      0.922331 -0.274221 -0.253365 -0.263471   \n",
       "\n",
       "     x.11.2    x.18.1      x.72     x.263     x.276  test_label  \n",
       "0 -0.276135 -0.421407  1.030376  3.553004 -0.244912           3  \n",
       "1 -0.276135 -0.421407  1.030376  3.553004 -0.244912           3  \n",
       "2 -0.276135  2.372959 -0.970501 -0.281447 -0.244912           3  \n",
       "3 -0.276135 -0.421407  1.030376 -0.281447 -0.244912           3  \n",
       "4 -0.276135  2.372959 -0.970501 -0.281447 -0.244912           3  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, ..., 3, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_t['training_label'].as_matrix()\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_in_hospital\n",
      "num_lab_procedures\n",
      "num_procedures\n",
      "num_medications\n",
      "number_outpatient\n",
      "number_emergency\n",
      "number_inpatient\n",
      "number_diagnoses\n",
      "readmitted J\n",
      "x\n",
      "x.2\n",
      "x.716\n",
      "x.1.1\n",
      "x.4.1\n",
      "x.5\n",
      "x.6\n",
      "x.7\n",
      "x.8\n",
      "x.718\n",
      "x.1.3\n",
      "x.2.3\n",
      "x.5.1\n",
      "x.719\n",
      "x.2.4\n",
      "x.5.2\n",
      "x.720\n",
      "x.6.3\n",
      "x.13.1\n",
      "x.3.5\n",
      "x.8.3\n",
      "x.11.2\n",
      "x.18.1\n",
      "x.72\n",
      "x.263\n",
      "x.276\n",
      "training_label\n",
      "\n",
      "time_in_hospital num_lab_procedures num_procedures num_medications number_outpatient number_emergency number_inpatient number_diagnoses x x.2 x.716 x.1.1 x.4.1 x.5 x.6 x.7 x.8 x.718 x.1.3 x.2.3 x.5.1 x.719 x.2.4 x.5.2 x.720 x.6.3 x.13.1 x.3.5 x.8.3 x.11.2 x.18.1 x.72 x.263 x.276 training_label\n"
     ]
    }
   ],
   "source": [
    "for k in train_t:\n",
    "    if k == \"training_label\":\n",
    "        print k\n",
    "        continue\n",
    "    if fk.has_key(k):\n",
    "        print k\n",
    "        continue\n",
    "    else:\n",
    "        print k,\"J\"\n",
    "        del train_t[k]\n",
    "print \n",
    "for k in train_t:\n",
    "    print k,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>x</th>\n",
       "      <th>x.2</th>\n",
       "      <th>...</th>\n",
       "      <th>x.6.3</th>\n",
       "      <th>x.13.1</th>\n",
       "      <th>x.3.5</th>\n",
       "      <th>x.8.3</th>\n",
       "      <th>x.11.2</th>\n",
       "      <th>x.18.1</th>\n",
       "      <th>x.72</th>\n",
       "      <th>x.263</th>\n",
       "      <th>x.276</th>\n",
       "      <th>training_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.784698</td>\n",
       "      <td>0.292344</td>\n",
       "      <td>-0.247341</td>\n",
       "      <td>-0.579531</td>\n",
       "      <td>-0.261276</td>\n",
       "      <td>-0.206332</td>\n",
       "      <td>-0.302125</td>\n",
       "      <td>-2.300532</td>\n",
       "      <td>-0.474839</td>\n",
       "      <td>0.545430</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.086339</td>\n",
       "      <td>-0.274604</td>\n",
       "      <td>-0.254056</td>\n",
       "      <td>-0.262402</td>\n",
       "      <td>-0.278155</td>\n",
       "      <td>-0.422036</td>\n",
       "      <td>-0.967392</td>\n",
       "      <td>-0.282538</td>\n",
       "      <td>-0.24487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.229955</td>\n",
       "      <td>0.292344</td>\n",
       "      <td>-0.816030</td>\n",
       "      <td>-1.302427</td>\n",
       "      <td>-0.261276</td>\n",
       "      <td>-0.206332</td>\n",
       "      <td>-0.302125</td>\n",
       "      <td>-2.300532</td>\n",
       "      <td>2.105940</td>\n",
       "      <td>-1.833381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920506</td>\n",
       "      <td>-0.274604</td>\n",
       "      <td>-0.254056</td>\n",
       "      <td>-0.262402</td>\n",
       "      <td>-0.278155</td>\n",
       "      <td>2.369422</td>\n",
       "      <td>-0.967392</td>\n",
       "      <td>-0.282538</td>\n",
       "      <td>-0.24487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568172</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>1.458724</td>\n",
       "      <td>-0.097600</td>\n",
       "      <td>-0.261276</td>\n",
       "      <td>-0.206332</td>\n",
       "      <td>2.922323</td>\n",
       "      <td>-0.712431</td>\n",
       "      <td>2.105940</td>\n",
       "      <td>-1.833381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920506</td>\n",
       "      <td>-0.274604</td>\n",
       "      <td>-0.254056</td>\n",
       "      <td>-0.262402</td>\n",
       "      <td>-0.278155</td>\n",
       "      <td>-0.422036</td>\n",
       "      <td>-0.967392</td>\n",
       "      <td>-0.282538</td>\n",
       "      <td>-0.24487</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.582825</td>\n",
       "      <td>0.442371</td>\n",
       "      <td>-0.247341</td>\n",
       "      <td>0.022883</td>\n",
       "      <td>-0.261276</td>\n",
       "      <td>-0.206332</td>\n",
       "      <td>-0.302125</td>\n",
       "      <td>0.875671</td>\n",
       "      <td>-0.474839</td>\n",
       "      <td>0.545430</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.086339</td>\n",
       "      <td>-0.274604</td>\n",
       "      <td>-0.254056</td>\n",
       "      <td>-0.262402</td>\n",
       "      <td>-0.278155</td>\n",
       "      <td>2.369422</td>\n",
       "      <td>-0.967392</td>\n",
       "      <td>-0.282538</td>\n",
       "      <td>-0.24487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.273913</td>\n",
       "      <td>-1.107909</td>\n",
       "      <td>-0.816030</td>\n",
       "      <td>-0.097600</td>\n",
       "      <td>2.465632</td>\n",
       "      <td>1.693810</td>\n",
       "      <td>2.922323</td>\n",
       "      <td>-0.183063</td>\n",
       "      <td>-0.474839</td>\n",
       "      <td>0.545430</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.086339</td>\n",
       "      <td>-0.274604</td>\n",
       "      <td>-0.254056</td>\n",
       "      <td>-0.262402</td>\n",
       "      <td>-0.278155</td>\n",
       "      <td>-0.422036</td>\n",
       "      <td>1.033688</td>\n",
       "      <td>-0.282538</td>\n",
       "      <td>-0.24487</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_in_hospital  num_lab_procedures  num_procedures  num_medications  \\\n",
       "0         -0.784698            0.292344       -0.247341        -0.579531   \n",
       "1          0.229955            0.292344       -0.816030        -1.302427   \n",
       "2          0.568172            0.092308        1.458724        -0.097600   \n",
       "3          1.582825            0.442371       -0.247341         0.022883   \n",
       "4          3.273913           -1.107909       -0.816030        -0.097600   \n",
       "\n",
       "   number_outpatient  number_emergency  number_inpatient  number_diagnoses  \\\n",
       "0          -0.261276         -0.206332         -0.302125         -2.300532   \n",
       "1          -0.261276         -0.206332         -0.302125         -2.300532   \n",
       "2          -0.261276         -0.206332          2.922323         -0.712431   \n",
       "3          -0.261276         -0.206332         -0.302125          0.875671   \n",
       "4           2.465632          1.693810          2.922323         -0.183063   \n",
       "\n",
       "          x       x.2       ...           x.6.3    x.13.1     x.3.5     x.8.3  \\\n",
       "0 -0.474839  0.545430       ...       -1.086339 -0.274604 -0.254056 -0.262402   \n",
       "1  2.105940 -1.833381       ...        0.920506 -0.274604 -0.254056 -0.262402   \n",
       "2  2.105940 -1.833381       ...        0.920506 -0.274604 -0.254056 -0.262402   \n",
       "3 -0.474839  0.545430       ...       -1.086339 -0.274604 -0.254056 -0.262402   \n",
       "4 -0.474839  0.545430       ...       -1.086339 -0.274604 -0.254056 -0.262402   \n",
       "\n",
       "     x.11.2    x.18.1      x.72     x.263    x.276  training_label  \n",
       "0 -0.278155 -0.422036 -0.967392 -0.282538 -0.24487               3  \n",
       "1 -0.278155  2.369422 -0.967392 -0.282538 -0.24487               3  \n",
       "2 -0.278155 -0.422036 -0.967392 -0.282538 -0.24487               2  \n",
       "3 -0.278155  2.369422 -0.967392 -0.282538 -0.24487               3  \n",
       "4 -0.278155 -0.422036  1.033688 -0.282538 -0.24487               2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, ..., 2, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train -1\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([ 4901, 17300, 32704]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54905, 34)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_t['training_label']\n",
    "X_train = train_t.as_matrix()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = test_t['test_label'].as_matrix()\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test -1\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([ 131, 3600, 9800]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_test,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13531, 34)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test_t['test_label']\n",
    "X_test = test_t.as_matrix()\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.061809063\n",
      "0.00432705879211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.67607715615992903"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "clf = LogisticRegression(C=1,tol=0.0000001,fit_intercept=True,class_weight='balanced',intercept_scaling=2.0,dual=True)\n",
    "old_ticks = time.time()\n",
    "clf.fit(X_train,y_train)\n",
    "new_ticks = time.time()\n",
    "print new_ticks - old_ticks\n",
    "old_ticks = time.time()\n",
    "pred = clf.predict(X_test)\n",
    "new_ticks = time.time()\n",
    "print new_ticks - old_ticks\n",
    "accuracy_score(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764183044434\n",
      "0.00631403923035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71753750646663217"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = tree.DecisionTreeClassifier(min_samples_leaf=25)\n",
    "old_ticks = time.time()\n",
    "clf1.fit(X_train,y_train)\n",
    "new_ticks = time.time()\n",
    "print new_ticks - old_ticks\n",
    "old_ticks = time.time()\n",
    "pred1 = clf1.predict(X_test)\n",
    "new_ticks = time.time()\n",
    "print new_ticks - old_ticks\n",
    "accuracy_score(pred1,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1047680378\n",
      "0.0542619228363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73475722415194733"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(min_samples_leaf=25,max_depth=25)\n",
    "old_ticks = time.time()\n",
    "clf2.fit(X_train,y_train)\n",
    "new_ticks = time.time()\n",
    "print new_ticks - old_ticks\n",
    "old_ticks = time.time()\n",
    "pred2 = clf2.predict(X_test)\n",
    "new_ticks = time.time()\n",
    "print new_ticks - old_ticks\n",
    "accuracy_score(pred2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf3s = svm.SVC(kernel='rbf')\n",
    "old_ticks = time.time()\n",
    "clf3s.fit(X_train,y_train)\n",
    "new_ticks = time.time()\n",
    "print new_ticks - old_ticks\n",
    "old_ticks = time.time()\n",
    "pred3 = clf3s.predict(X_test)\n",
    "new_ticks = time.time()\n",
    "print new_ticks - old_ticks\n",
    "accuracy_score(pred3,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54905, 3)\n",
      "(13531, 3)\n"
     ]
    }
   ],
   "source": [
    "y_t = []\n",
    "for k in y_train:\n",
    "    ys = [0,0,0]\n",
    "    ys[k] = 1\n",
    "    y_t.append(ys)\n",
    "\n",
    "y_te = []\n",
    "for k in y_test:\n",
    "    ys = [0,0,0]\n",
    "    ys[k] = 1\n",
    "    y_te.append(ys)\n",
    "y_t = np.array(y_t)\n",
    "y_te = np.array(y_te)\n",
    "print y_t.shape\n",
    "print y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 0, 'completed out of', 501, 'loss:', 5464.6685947179794)\n",
      "('Epoch', 100, 'completed out of', 501, 'loss:', 588.5840830206871)\n",
      "('Epoch', 200, 'completed out of', 501, 'loss:', 586.66650831699371)\n",
      "('Epoch', 300, 'completed out of', 501, 'loss:', 585.73793029785156)\n",
      "('Epoch', 400, 'completed out of', 501, 'loss:', 585.47006869316101)\n",
      "('Epoch', 500, 'completed out of', 501, 'loss:', 585.38869827985764)\n",
      "('Accuracy:', 0.72958392)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)\n",
    "\n",
    "n_nodes_hl1 = 10\n",
    "n_nodes_hl2 = 5\n",
    "'''n_nodes_hl3 = 10\n",
    "n_nodes_hl4 = 10\n",
    "n_nodes_hl5 = 10\n",
    "n_nodes_hl6 = 10\n",
    "n_nodes_hl7 = 10\n",
    "n_nodes_hl8 = 10\n",
    "n_nodes_hl9 = 10\n",
    "n_nodes_hl10 = 10\n",
    "n_nodes_hl11 = 10\n",
    "n_nodes_hl12 = 10'''\n",
    "\n",
    "n_classes = 3\n",
    "batch_size = 79\n",
    "\n",
    "x = tf.placeholder('float', [None, X_test.shape[1]])\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "def neural_network_model(data):\n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([X_test.shape[1], n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "    '''hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "    hidden_4_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_nodes_hl4])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl4]))}\n",
    "    hidden_5_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl4, n_nodes_hl5])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl5]))}\n",
    "    hidden_6_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl5, n_nodes_hl6])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl6]))}\n",
    "    hidden_7_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl6, n_nodes_hl7])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl7]))}\n",
    "    hidden_8_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl7, n_nodes_hl8])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl8]))}\n",
    "    hidden_9_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl8, n_nodes_hl9])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl9]))}\n",
    "    hidden_10_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl9, n_nodes_hl10])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl10]))}\n",
    "    hidden_11_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl10, n_nodes_hl11])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl11]))}\n",
    "    hidden_12_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl11, n_nodes_hl12])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl12]))}'''\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_classes])),\n",
    "                    'biases':tf.Variable(tf.random_normal([n_classes])),}\n",
    "\n",
    "\n",
    "    l1 = tf.add(tf.matmul(data,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    '''l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "    l4 = tf.add(tf.matmul(l3,hidden_4_layer['weights']), hidden_4_layer['biases'])\n",
    "    l4 = tf.nn.relu(l4)\n",
    "    l5 = tf.add(tf.matmul(l4,hidden_5_layer['weights']), hidden_5_layer['biases'])\n",
    "    l5 = tf.nn.relu(l5)\n",
    "    l6 = tf.add(tf.matmul(l5,hidden_6_layer['weights']), hidden_6_layer['biases'])\n",
    "    l6 = tf.nn.relu(l6)\n",
    "    l7 = tf.add(tf.matmul(l6,hidden_7_layer['weights']), hidden_7_layer['biases'])\n",
    "    l7 = tf.nn.relu(l7)\n",
    "    l8 = tf.add(tf.matmul(l7,hidden_8_layer['weights']), hidden_8_layer['biases'])\n",
    "    l8 = tf.nn.relu(l8)\n",
    "    l9 = tf.add(tf.matmul(l8,hidden_9_layer['weights']), hidden_9_layer['biases'])\n",
    "    l9 = tf.nn.relu(l9)\n",
    "    l10 = tf.add(tf.matmul(l9,hidden_10_layer['weights']), hidden_10_layer['biases'])\n",
    "    l10 = tf.nn.relu(l10)\n",
    "    l11 = tf.add(tf.matmul(l10,hidden_11_layer['weights']), hidden_11_layer['biases'])\n",
    "    l11 = tf.nn.relu(l11)\n",
    "    l12 = tf.add(tf.matmul(l11,hidden_12_layer['weights']), hidden_12_layer['biases'])\n",
    "    l12 = tf.nn.relu(l12)'''\n",
    "    output = tf.matmul(l2,output_layer['weights']) + output_layer['biases']\n",
    "    \n",
    "    return output\n",
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = neural_network_model(x)\n",
    "    # OLD VERSION:\n",
    "    #cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(prediction,y) )\n",
    "    # NEW:\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    hm_epochs = 501\n",
    "    with tf.Session() as sess:\n",
    "        # OLD:\n",
    "        #sess.run(tf.initialize_all_variables())\n",
    "        # NEW:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            i = 0\n",
    "            while i < len(X_train):\n",
    "                start = i\n",
    "                end = i+batch_size\n",
    "                batch_x = np.array(X_train[start:end])\n",
    "                batch_y = np.array(y_t[start:end])\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "                epoch_loss += c\n",
    "                i+=batch_size\n",
    "            if epoch%100==0:\n",
    "                print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:',accuracy.eval({x:X_test, y:y_te}))\n",
    "\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 0, 'completed out of', 501, 'loss:', 606.3062627017498)\n",
      "('Epoch', 100, 'completed out of', 501, 'loss:', 515.94872909784317)\n",
      "('Epoch', 200, 'completed out of', 501, 'loss:', 453.65660950541496)\n",
      "('Epoch', 300, 'completed out of', 501, 'loss:', 410.71858951449394)\n",
      "('Epoch', 400, 'completed out of', 501, 'loss:', 384.1917465031147)\n",
      "('Epoch', 500, 'completed out of', 501, 'loss:', 360.53733158111572)\n",
      "('Accuracy:', 0.8017146)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "epochs = 501\n",
    "n_classes = 3\n",
    "batch_size = 79\n",
    "chunk_size = 17\n",
    "n_chunks = 2\n",
    "rnn_size = 122\n",
    "#n_preds = None\n",
    "x = tf.placeholder('float',[None,n_chunks,chunk_size])\n",
    "y = tf.placeholder('float')\n",
    "def recurrent_neural_network(x):\n",
    "    layer = {'weights':tf.Variable(tf.random_normal([rnn_size,n_classes])),\n",
    "             'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    x = tf.unstack(x, n_chunks, 1)\n",
    "    #print x.shape\n",
    "    with tf.variable_scope('cell_def'):\n",
    "        lstm_cell = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    with tf.variable_scope('rnnf_def'):\n",
    "        outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    output = tf.matmul(outputs[-1],layer['weights']) + layer['biases']\n",
    "\n",
    "    return output\n",
    "def train_neural_network(x):\n",
    "    prediction = recurrent_neural_network(x)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y) )\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.03,beta1=0.9,beta2=0.999,epsilon=1e-09,use_locking=True,name='Adam').minimize(cost)\n",
    "    \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            i = 0\n",
    "            while i<len(X_train):\n",
    "                start = i\n",
    "                end = i + batch_size\n",
    "                #print(start,end)\n",
    "                epoch_x, epoch_y = X_train[start:end],y_t[start:end]\n",
    "                epoch_x = epoch_x.reshape((batch_size,n_chunks,chunk_size))\n",
    "                #print epoch_x.shape\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "                i += batch_size\n",
    "            if epoch%100==0:\n",
    "                print('Epoch', epoch, 'completed out of',epochs,'loss:',epoch_loss)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:',accuracy.eval({x:X_test.reshape((-1, n_chunks, chunk_size)), y:y_te}))\n",
    "        pred = sess.run(prediction,feed_dict={x:X_test.reshape((-1, n_chunks, chunk_size))})\n",
    "        corr = tf.argmax(pred,1)\n",
    "        corr = sess.run(corr)\n",
    "        #print(corr)\n",
    "        #n_preds = corr\n",
    "        #k = [i+1 for i in range(len(corr))]\n",
    "        #yg = pd.DataFrame({'ImageId':pd.Series(k),'Label':pd.Series(corr)})\n",
    "        #yg.to_csv('ans.csv',index=False)\n",
    "        return pred,corr\n",
    "y_score_rnn,pred_rnn = train_neural_network(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
